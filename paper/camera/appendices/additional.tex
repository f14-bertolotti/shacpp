\section{Additional Experiments}\label{apx:experiments}

Finally, we present the results of the experiments with the MLP architecture in \Cref{apx:fig:experiments-mlp}. We observe that the MLP architecture underperforms compared to the Transformer architecture. Nonetheless, \fname{} often outperforms PPO and generally performs on par with SHAC.

Interestingly, the Discovery scenario appears to be the most challenging, as none of the algorithms (PPO and \fname{}) are able to make any meaningful progress. This may be caused by the sample inefficiency of the MLP architecture, combined with the fact that the world model cannot access the full state.

The only scenario where SHAC outperforms \fname{} is the Transport scenario. This may be due to the MLP's inability to overcome the gradient noise from the world model.

To check also the scalability of \fname{} we run the experiments with up to $20$ agents in the Transport scenario. The results are shown in \Cref{apx:fig:experiments-mlp}. We observe that \fname{} is able to scale well with the number of agents, achieving good results even with $20$ agents, also in this case similarly to SHAC.
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figs/main-mlp.pdf}
    \caption{Comparison between \fname{}, PPO, and SHAC for increasing number of agents for Dispersion, Transport, Discovery, and Sampling scenarios with the MLP architecture.
    We show the mean and standard deviation of the normalized rewards across $3$ runs.
    }\vspace{0.5cm}
    \label{apx:fig:experiments-mlp}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figs/transport-high-agents.pdf}
    \caption{Comparison between \fname{} and SHAC for increasing number of agents (up to 20) in the Transport scenario with the Transformer architecture. Results demonstrate the scalability of both approaches as the number of agents increases.}\label{apx:fig:experiments-mlp-20}
    
    \vspace{0.5cm}
\end{figure}


