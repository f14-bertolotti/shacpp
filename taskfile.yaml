version: '3'

env:
  PYTHON: /usr/bin/python3.11
  DEVICE: cuda:0

tasks:

  dependencies: 
    sources:
      - requirements.txt
    generates:
      - venv/.builded
    cmds:
      - rm -rf venv
      - $PYTHON -m venv venv
      - venv/bin/python3 -m pip install -r requirements.txt
      - touch venv/.builded

  ppo-scattered:
    deps: 
      - dependencies
    sources:
      - src/**/*.py
    generates:
      - models/ppo/.trained
    cmds:
      - mkdir -p models/ppo
      - venv/bin/python3 src/cli.py
        cli storage     default
        cli agent       transformer-agent
        cli environment scattered
        cli algorithm   ppo 
        cli algorithm   ppo trajectory default --steps 32
        cli algorithm   ppo optimizer  adam
        cli algorithm   ppo scheduler  cosine
        cli logger      file --path models/ppo/train.log
        cli callback    base
        cli callback    checkpointer --path models/ppo/agent.pkl 
        cli save-configuration    --path models/ppo/configuration.json
        cli train 
      - cp ./taskfile.yaml models/ppo/
      - touch models/ppo/.trained

  shac-learnable-reward:
    deps: 
      - dependencies
    sources:
      - src/**/*.py
    generates:
      - models/shac-learnable-reward/.trained
    cmds:
      - mkdir -p models/shac-learnable-reward
      - venv/bin/python3 src/cli.py
        cli storage     default
        cli agent       transformer-agent
        cli environment scattered-learnable-reward 
        cli environment scattered-learnable-reward reward transformer-reward
        cli environment scattered-learnable-reward optimizer adam --learning-rate 0.0001
        cli environment scattered-learnable-reward scheduler constant
        cli algorithm   shac 
        cli algorithm   shac trajectory default 
        cli algorithm   shac trajectory optimizer adam --learning-rate 0.0005
        cli algorithm   shac trajectory scheduler constant 
        cli algorithm   shac optimizer  adam --learning-rate 0.0001
        cli algorithm   shac scheduler  cosine --lrmin 0.000001
        cli logger      file --path models/shac-learnable-reward/train.log
        cli callback    base-shac-learnable-reward
        cli callback    checkpointer --path models/shac-learnable-reward/agent.pkl 
        cli save-configuration --path models/shac-learnable-reward/configuration.json
        cli train 
      - cp ./taskfile.yaml models/shac-learnable-reward/
      - touch models/shac-learnable-reward/.trained

  ppo-dispersion:
    deps: 
      - dependencies
    sources:
      - src/**/*.py
    vars:
      FOLDER   : ppo-dispersion
    generates:
      - models/{{.FOLDER}}/.trained
    cmds:
      - mkdir -p models/{{.FOLDER}}
      - venv/bin/python3 src/cli.py
        cli environment dispersion --envs 512 --agents 3 --seed 42
        cli agent mlp-agent --shared false --layers 1 --hidden-size 64
        cli algorithm ppo --batch-size 1024 --epochs 4
        cli algorithm ppo trajectory default --reset-prb .33 --feedback true --steps 64
        cli algorithm ppo optimizer  adam --learning-rate 0.001
        cli algorithm ppo scheduler  cosine --lrmin 0.0001 --tmax 50
        cli callback trainlog           --path models/{{.FOLDER}}/train.log
        cli callback evaluate           --path models/{{.FOLDER}}/valid.log --ete 10 --steps 64 --size 512
        cli callback checkpointer       --path models/{{.FOLDER}}/agent.pkl --ete 10
        cli callback save-configuration --path models/{{.FOLDER}}/configuration.json
        cli train --episodes 1000 --seed 42
      - cp ./taskfile.yaml models/{{.FOLDER}}/
      - touch models/{{.FOLDER}}/.trained

  ppo-dispersion-viz:
    deps:
      - dependencies
    sources:
      - models/**/*.log
    generates:
      - models/ppo-dispersion.png
    vars:
      SAMPLES: '{{default 1000 .SAMPLES}}'
    cmds:
      - SAMPLES={{.SAMPLES}}; eval "jet init --shape 1 1 "$(find models -maxdepth 1 -type d -name 'ppo-dispersion-*' -printf " jet line --samples ${SAMPLES} --input-path %p/train.log --x message/episode --y message/reward --label %p")" jet plot --show True --output-path models/ppo-dispersion.png"

